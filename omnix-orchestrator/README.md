# üîÑ OmnixLang Orchestrator

**Visual Pipeline Builder for Heterogeneous Data Systems**

The OmnixLang Orchestrator is a polyglot data pipeline platform that enables visual construction and execution of complex workflows using Python, JavaScript, SQL, and other languages in a single pipeline.

## üöÄ Features

### Phase 0 - Foundation (Current)
‚úÖ **Visual Graph IDE** - Drag-and-drop pipeline designer  
‚úÖ **Polyglot Adapters** - Python, JavaScript, SQL execution  
‚úÖ **Local Execution Engine** - Run pipelines locally  
‚úÖ **Real-time Monitoring** - Live execution feedback  
‚úÖ **RESTful API** - Programmatic access  
‚úÖ **WebSocket Support** - Live updates  

### Core Capabilities
- **Language Agnostic**: Run Python, JS, SQL in one pipeline
- **Visual Programming**: No-code/low-code interface  
- **Data Transformation**: Built-in ETL operations
- **Error Handling**: Comprehensive validation and error reporting
- **Code Generation**: Export to OmnixLang source code

## üì¶ Installation

### Prerequisites
- Node.js >= 16.0.0
- Python >= 3.8 (optional, for Python nodes)

### Quick Start
```bash
# Clone or download the orchestrator
cd omnix-orchestrator

# Install dependencies
npm install

# Start the server
npm start

# Or run directly
node index.js start
```

### Test the System
```bash
# Run polyglot pipeline test
npm test

# Or run directly  
node test-pipeline.js
```

## üéÆ Usage

### Web Interface
1. Open http://localhost:3000 in your browser
2. Drag nodes from the palette to the canvas
3. Connect nodes to create data flow
4. Configure node properties
5. Click "Run Pipeline" to execute

### Supported Node Types
- **üì• Input**: Load data from files, APIs, databases
- **üêç Python**: Execute Python data processing code
- **‚ö° JavaScript**: Run JavaScript transformations  
- **üìä SQL**: Query databases with SQL
- **‚öôÔ∏è Transform**: Built-in data transformations
- **üì§ Output**: Save results to various destinations

### API Usage

#### Execute Single Node
```bash
curl -X POST http://localhost:3000/api/execute \
  -H "Content-Type: application/json" \
  -d '{
    "type": "python",
    "code": "return [x**2 for x in range(5)]",
    "data": null
  }'
```

#### Execute Pipeline
```bash
curl -X POST http://localhost:3000/api/pipeline/execute \
  -H "Content-Type: application/json" \
  -d '{
    "nodes": [...],
    "connections": [...]
  }'
```

### Programmatic Usage
```javascript
const { executeCode, executePipeline } = require('./index');

// Execute code in different languages
const pythonResult = await executeCode('python', 'return [1,2,3]');
const jsResult = await executeCode('javascript', 'return data.map(x => x * 2)', [1,2,3]);
const sqlResult = await executeCode('sql', 'SELECT * FROM users LIMIT 5');

// Execute complete pipeline
const pipelineResult = await executePipeline({
  nodes: [...],
  connections: [...]
});
```

## üèóÔ∏è Architecture

### Core Components
```
omnix-orchestrator/
‚îú‚îÄ‚îÄ adapters/           # Polyglot language adapters
‚îÇ   ‚îú‚îÄ‚îÄ base-adapter.js    # Abstract base class
‚îÇ   ‚îú‚îÄ‚îÄ python-adapter.js  # Python execution
‚îÇ   ‚îú‚îÄ‚îÄ javascript-adapter.js # JavaScript sandbox
‚îÇ   ‚îú‚îÄ‚îÄ sql-adapter.js     # SQL query engine
‚îÇ   ‚îî‚îÄ‚îÄ index.js          # Adapter manager
‚îú‚îÄ‚îÄ engine/             # Execution engine
‚îÇ   ‚îî‚îÄ‚îÄ pipeline-executor.js # Pipeline orchestration
‚îú‚îÄ‚îÄ ide/                # Web-based Graph IDE
‚îÇ   ‚îî‚îÄ‚îÄ graph-editor.html # Visual pipeline builder
‚îú‚îÄ‚îÄ server.js           # HTTP/WebSocket server
‚îú‚îÄ‚îÄ index.js           # Main entry point
‚îî‚îÄ‚îÄ test-pipeline.js   # Demo and tests
```

### Adapter Architecture
Each adapter implements the `BaseAdapter` interface:
- `init()` - Initialize runtime
- `execute(code, data)` - Run code with input data  
- `validate(code)` - Check syntax
- `transformData()` - Convert between formats

### Execution Flow
1. **Parse Pipeline**: Validate nodes and connections
2. **Topological Sort**: Determine execution order
3. **Execute Nodes**: Run each node with adapter
4. **Data Flow**: Pass results between connected nodes
5. **Collect Results**: Aggregate final outputs

## üîß Configuration

### Environment Variables
```bash
PORT=3000                    # Server port
NODE_ENV=development        # Environment
PYTHON_PATH=python         # Python executable
ENABLE_SQL_WRITES=false    # Allow SQL modifications
```

### Adapter Configuration
```javascript
const { AdapterManager } = require('./adapters');

const manager = new AdapterManager();

// Configure Python adapter
await manager.registerAdapter('python', new PythonAdapter({
  pythonPath: '/usr/bin/python3',
  timeout: 30000
}));

// Configure SQL adapter  
await manager.registerAdapter('sql', new SQLAdapter({
  dialect: 'postgres',
  connection: { host: 'localhost', ... },
  allowModifying: false
}));
```

## üß™ Examples

### ETL Pipeline
```javascript
const etlPipeline = {
  nodes: [
    {
      id: 1,
      type: 'input',
      properties: { source: 'file', path: 'data.csv', format: 'csv' }
    },
    {
      id: 2, 
      type: 'python',
      properties: {
        code: `
import pandas as pd
df = pd.DataFrame(data)
df['processed'] = True
return df.to_dict('records')
`
      }
    },
    {
      id: 3,
      type: 'output', 
      properties: { destination: 'file', path: 'output.json', format: 'json' }
    }
  ],
  connections: [
    { from: { id: 1 }, to: { id: 2 } },
    { from: { id: 2 }, to: { id: 3 } }
  ]
};
```

### Data Analysis Pipeline
```javascript
const analysisPipeline = {
  nodes: [
    { id: 1, type: 'input', properties: { source: 'database', query: 'SELECT * FROM sales' } },
    { id: 2, type: 'python', properties: { code: 'return data.groupby("region").sum()' } },
    { id: 3, type: 'javascript', properties: { code: 'return data.map(r => ({...r, growth: r.current/r.previous}))' } },
    { id: 4, type: 'sql', properties: { query: 'INSERT INTO reports (data) VALUES (?)' } }
  ],
  connections: [
    { from: { id: 1 }, to: { id: 2 } },
    { from: { id: 2 }, to: { id: 3 } },
    { from: { id: 3 }, to: { id: 4 } }
  ]
};
```

## üö¶ Business Model

### Open Core Strategy
- **Free Tier**: Graph IDE, basic adapters, local execution
- **Pro Tier**: Distributed execution, monitoring, team features  
- **Enterprise**: Compliance, custom connectors, SLA support

### Current Phase: Phase 0
**Goal**: Free graph IDE with polyglot adapters  
**Target**: 1,000 installs, 50 GitHub stars, 3 case studies

### Next Phase: Phase 1 
**Goal**: Launch paid Omnix Orchestrator
**Features**: Distributed execution, secrets management, audit logs
**Pricing**: $299/month (Team), $999/month (Business)

## üîí Security

### Sandboxing
- JavaScript code runs in VM sandbox with timeout
- Python code executes in subprocess with resource limits
- SQL queries are validated and can be restricted to read-only

### Best Practices
- Never log sensitive data
- Validate all input parameters
- Use secure communication channels
- Implement proper authentication for production

## ü§ù Contributing

### Development Setup
```bash
git clone https://github.com/omnixlang/omnix-orchestrator
cd omnix-orchestrator
npm install
npm run dev
```

### Adding New Adapters
1. Extend `BaseAdapter` class
2. Implement required methods (`init`, `execute`, `validate`)
3. Register in `AdapterManager`
4. Add tests and documentation

### Architecture Decisions
- Modular adapter system for easy extension
- Event-driven execution with real-time updates
- RESTful API with WebSocket enhancements
- Browser-first design with offline capabilities

## üìä Performance

### Benchmarks
- **Startup Time**: < 2 seconds
- **Node Execution**: 50-500ms per node
- **Pipeline Overhead**: < 100ms
- **Memory Usage**: 50-200MB base

### Scaling
- **Concurrent Pipelines**: 10+ on standard hardware
- **Node Limit**: 100+ nodes per pipeline  
- **Data Throughput**: 1M+ records/minute

## üõ£Ô∏è Roadmap

### Phase 1 (Months 1-3)
- [ ] Distributed execution engine
- [ ] User authentication & authorization
- [ ] Team collaboration features
- [ ] Advanced monitoring & alerting
- [ ] Secrets management

### Phase 2 (Months 4-12) 
- [ ] Enterprise connectors (Snowflake, Databricks, Kafka)
- [ ] Marketplace for community nodes
- [ ] Advanced scheduling & triggers
- [ ] Data lineage tracking
- [ ] Cost optimization tools

### Phase 3 (Years 1-3)
- [ ] SOC2 Type II compliance
- [ ] Multi-cloud orchestration
- [ ] AI-powered optimization
- [ ] Real-time streaming pipelines
- [ ] Global deployment network

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details.

## üîó Links

- **Website**: https://omnixlang.dev/orchestrator
- **Documentation**: https://docs.omnixlang.dev/orchestrator  
- **GitHub**: https://github.com/omnixlang/omnix-orchestrator
- **Issues**: https://github.com/omnixlang/omnix-orchestrator/issues
- **Discord**: https://discord.gg/omnixlang

---

**"Making Complex Simple, One Pipeline at a Time"** üéØ